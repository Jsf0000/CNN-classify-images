{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying otsu segmentation and normalize the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImage(imgdir,sizeRows,sizeColumns):\n",
    "    img = Image.open(imgdir)\n",
    "    img = img.resize((sizeRows,sizeColumns),Image.ANTIALIAS)\n",
    "    img  = np.asarray(img.convert('L'))\n",
    "    val = threshold_otsu(np.array(img))\n",
    "    otsuApplied = np.array(img)>val\n",
    "    return otsuApplied.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories with training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR1 = \"Train/Sedan/\"\n",
    "DIR2 = \"Train/buses/\"\n",
    "DIR3 = \"Train/motorcycles/\"\n",
    "paths = [DIR1,DIR2,DIR3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vector for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_img(name):\n",
    "    if \"sedan\" in name: #label for vehicules (specifically sedan)\n",
    "        return np.array([1,0,0])\n",
    "    elif \"bus\" in name: #Label for buses\n",
    "        return np.array([0,1,0])\n",
    "    elif \"moto\" in name: #Label for motorcycles\n",
    "        return np.array([0,0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_training_data():\n",
    "    train_data = [] \n",
    "    for tempPath in paths:\n",
    "        for img in os.listdir(tempPath):\n",
    "            label = label_img(img)  # read the images and assigned the label\n",
    "            path = os.path.join(tempPath, img)\n",
    "            if \"DS_Store\" not in path: #validate for Mac Os users\n",
    "                train_data.append([normalizeImage(path,IMG_SIZE,IMG_SIZE), label]) #normaliza data and \n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n"
     ]
    }
   ],
   "source": [
    "train_data = load_training_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image after segmentation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x108fdfc88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1b70cf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[10][0], cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divede training columns and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_data])\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries used for keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the keras model with the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model with training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2451/2451 [==============================] - 341s 139ms/step - loss: 0.8462 - acc: 0.6728\n",
      "Epoch 2/5\n",
      "2451/2451 [==============================] - 335s 137ms/step - loss: 0.4662 - acc: 0.8311\n",
      "Epoch 3/5\n",
      "2451/2451 [==============================] - 333s 136ms/step - loss: 0.3520 - acc: 0.8715\n",
      "Epoch 4/5\n",
      "2451/2451 [==============================] - 349s 142ms/step - loss: 0.2372 - acc: 0.9106\n",
      "Epoch 5/5\n",
      "2451/2451 [==============================] - 345s 141ms/step - loss: 0.2282 - acc: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1dd692b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainImages, trainLabels, batch_size = 10, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load specific image for be consult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_test_data(path):\n",
    "    return np.array(normalizeImage(path,IMG_SIZE,IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test a specific image:\n",
    "[0] : car\n",
    "[1] : bus\n",
    "[2] : Motorcycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model.predict_classes(load_test_data(\"/Users/jasonsolano/Downloads/carTest1.jpg\"))\n",
    "ynew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories for test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR1 = \"Test/cars/\"\n",
    "DIR2 = \"Test/buses/\"\n",
    "DIR3 = \"Test/motorcycles/\"\n",
    "paths = [DIR1,DIR2,DIR3]\n",
    "test_data = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/PIL/Image.py:916: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_test_data():\n",
    "    for tempPath in paths:\n",
    "        for img in os.listdir(tempPath): #list the images of directory\n",
    "            if('cars' in tempPath): #assigned labels\n",
    "                label = np.array([1,0,0])\n",
    "            elif('buses' in tempPath):\n",
    "                label = np.array([0,1,0])\n",
    "            else:\n",
    "                label = np.array([0,0,1])\n",
    "            path = os.path.join(tempPath, img)\n",
    "            if \"DS_Store\" not in path: #validate for Mac Os users\n",
    "                test_data.append([normalizeImage(path,IMG_SIZE,IMG_SIZE), label]) #normaliza data  \n",
    "    shuffle(test_data)\n",
    "    return test_data\n",
    "load_test_data()\n",
    "testImages = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "testLabels = np.array([i[1] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of array with the test images\n",
    "len(testImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for get the accuracy with the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 107ms/step\n",
      "79.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testImages, testLabels, verbose = 1)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
