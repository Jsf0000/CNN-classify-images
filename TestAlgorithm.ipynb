{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying otsu segmentation and normalize the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImage(imgdir,sizeRows,sizeColumns):\n",
    "    img = Image.open(imgdir)\n",
    "    img = img.resize((sizeRows,sizeColumns),Image.ANTIALIAS)\n",
    "    img  = np.asarray(img.convert('L'))\n",
    "    val = threshold_otsu(np.array(img))\n",
    "    otsuApplied = np.array(img)>val\n",
    "    return otsuApplied.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR1 = \"/Users/jasonsolano/Documents/TrainingImages/Sedan/\"\n",
    "DIR2 = \"/Users/jasonsolano/Documents/TrainingImages/buses/\"\n",
    "DIR3 = \"/Users/jasonsolano/Documents/TrainingImages/motorcycles/\"\n",
    "paths = [DIR1,DIR2,DIR3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Want to know how we should format the height x width image data dimensions\n",
    "# # for inputting to a keras model\n",
    "# def get_size_statistics():\n",
    "#     heights = []\n",
    "#     widths = []\n",
    "#     img_count = 0\n",
    "#     for tempPath in paths:\n",
    "#         for img in os.listdir(tempPath):\n",
    "#             path = os.path.join(tempPath, img)\n",
    "#             if \"DS_Store\" not in path:\n",
    "#                 data = np.array(Image.open(path))\n",
    "#                 heights.append(data.shape[0])\n",
    "#                 widths.append(data.shape[1])\n",
    "#                 img_count += 1\n",
    "#     avg_height = sum(heights) / len(heights)\n",
    "#     avg_width = sum(widths) / len(widths)\n",
    "#     print(\"Average Height: \" + str(avg_height))\n",
    "#     print(\"Max Height: \" + str(max(heights)))\n",
    "#     print(\"Min Height: \" + str(min(heights)))\n",
    "#     print('\\n')\n",
    "#     print(\"Average Width: \" + str(avg_width))\n",
    "#     print(\"Max Width: \" + str(max(widths)))\n",
    "#     print(\"Min Width: \" + str(min(widths)))\n",
    "\n",
    "# get_size_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build vector for labels\n",
    "def label_img(name):\n",
    "    if \"sedan\" in name: #label for vehicules (specifically sedan)\n",
    "        return np.array([1,0,0])\n",
    "    elif \"bus\" in name: #Label for buses\n",
    "        return np.array([0,1,0])\n",
    "    elif \"moto\" in name: #Label for motorcycles\n",
    "        return np.array([0,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_training_data():\n",
    "    train_data = [] \n",
    "    for tempPath in paths:\n",
    "        for img in os.listdir(tempPath):\n",
    "            label = label_img(img)  # read the images and assigned the label\n",
    "            path = os.path.join(tempPath, img)\n",
    "            if \"DS_Store\" not in path: #validate for Mac Os users\n",
    "                train_data.append([normalizeImage(path,IMG_SIZE,IMG_SIZE), label]) #normaliza data and \n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10efbdd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2b004668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[200][0], cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_data])\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2451/2451 [==============================] - 348s 142ms/step - loss: 0.8136 - acc: 0.6932\n",
      "Epoch 2/5\n",
      "2451/2451 [==============================] - 349s 142ms/step - loss: 0.4883 - acc: 0.8250\n",
      "Epoch 3/5\n",
      "2451/2451 [==============================] - 342s 140ms/step - loss: 0.3420 - acc: 0.8747\n",
      "Epoch 4/5\n",
      "2451/2451 [==============================] - 342s 139ms/step - loss: 0.2560 - acc: 0.9045\n",
      "Epoch 5/5\n",
      "2451/2451 [==============================] - 345s 141ms/step - loss: 0.1549 - acc: 0.9421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c18f25470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainImages, trainLabels, batch_size = 10, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Test Set\n",
    "TEST_DIR = './test'\n",
    "def load_test_data(path):\n",
    "    return np.array(normalizeImage(path,IMG_SIZE,IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict_classes(load_test_data(\"/Users/jasonsolano/Downloads/motot.jpg\"))\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "IMG_SIZE = 300\n",
    "camera = data.camera()\n",
    "img = Image.open(\"/Users/jasonsolano/Documents/TrainingImages/buses/coaster.jpeg\")\n",
    "img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "img  = np.asarray(img.convert('L'))\n",
    "# print(np.array(img))\n",
    "# camera = data.camera(np.array(img))\n",
    "Segmentation = filters.threshold_otsu(np.array(img))\n",
    "ax[2].imshow(Segmentation, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Thresholded')\n",
    "ax[2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR1 = \"/Users/jasonsolano/Documents/testCNN/cars/\"\n",
    "DIR2 = \"/Users/jasonsolano/Documents/testCNN/buses/\"\n",
    "DIR3 = \"/Users/jasonsolano/Documents/testCNN/motorcycles/\"\n",
    "paths = [DIR1,DIR2,DIR3]\n",
    "test_data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/PIL/Image.py:916: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_test_data():\n",
    "    for tempPath in paths:\n",
    "        for img in os.listdir(tempPath): #list the images of directory\n",
    "            if('cars' in tempPath): #assigned labels\n",
    "                label = np.array([1,0,0])\n",
    "            elif('buses' in tempPath):\n",
    "                label = np.array([0,1,0])\n",
    "            else:\n",
    "                label = np.array([0,0,1])\n",
    "            path = os.path.join(tempPath, img)\n",
    "            if \"DS_Store\" not in path: #validate for Mac Os users\n",
    "                test_data.append([normalizeImage(path,IMG_SIZE,IMG_SIZE), label]) #normaliza data  \n",
    "    shuffle(test_data)\n",
    "    return test_data\n",
    "load_test_data()\n",
    "testImages = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "testLabels = np.array([i[1] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 81ms/step\n",
      "82.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(testImages, testLabels, verbose = 1)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from skimage import data\n",
    "# from skimage.filters import threshold_otsu\n",
    "# from skimage.filters import threshold_yen\n",
    "# from skimage.filters import try_all_threshold\n",
    "# IMG_SIZE = 300\n",
    "\n",
    "# img = Image.open(\"/Users/jasonsolano/Documents/TrainingImages/motorcycles/moto6.jpg\")\n",
    "# img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "\n",
    "# image = data.camera()\n",
    "# image  = np.asarray(img.convert('L'))\n",
    "# print(np.shape(image))\n",
    "# fig, ax = try_all_threshold(image, figsize=(10, 8), verbose=False)\n",
    "# val = threshold_otsu(np.array(image))\n",
    "# otsuApplied = np.array(image)>val\n",
    "\n",
    "# print(otsuApplied)\n",
    "# print(np.shape(otsuApplied.astype(int)))\n",
    "\n",
    "# plt.imshow(otsuApplied, cmap='gray', interpolation='nearest')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "def normalizeImages(imgdir,sizeRows,sizeColumns):\n",
    "    \n",
    "    img = Image.open(imgdir) # get image\n",
    "    img = img.resize((sizeRows,sizeColumns),Image.ANTIALIAS) # reshape the image size \n",
    "    \n",
    "    #draw image\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    \n",
    "    \n",
    "    img  = np.asarray(img.convert('L')) # get the scalegray mask of image\n",
    "    \n",
    "    val = threshold_otsu(np.array(img)) # get the value of otsu method\n",
    "    \n",
    "    otsuApplied = np.array(img)>val # applied the threshold tehcnique\n",
    "    \n",
    "    #draw image\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(otsuApplied, cmap='gray', interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeImages(\"/Users/jasonsolano/Documents/TrainingImages/Sedan/sedan11.jpg\",300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
